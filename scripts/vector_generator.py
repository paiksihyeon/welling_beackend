"""
Welling Vector Generator (CSV â†’ E5 ë²¡í„° ë³€í™˜)
-----------------------------------
âœ… ì—­í• :
- ì •ì±… ë¬¸ì„œ â†’ policy_vectors.json ìƒì„±
- ì§€ì—­ë³„ CSV íŒŒì¼ â†’ {region}_vectors_e5.json ìƒì„±
- CSVëŠ” app/files í´ë”ì— "{ì§€ì—­ëª…}.csv" í˜•íƒœë¡œ ì¡´ì¬í•´ì•¼ í•¨

âœ… CSV ìš”êµ¬ì‚¬í•­:
- ì»¬ëŸ¼: topic, text
  ì˜ˆì‹œ:
  topic,text
  ì£¼ê±°í™˜ê²½,ë¶€ì‚°ì˜ ì „ì„¸ê°€ê²©ì´ ë„ˆë¬´ ë†’ì•„ìš”
  ë…¸ë™ê²½ì œ,ì¼ìë¦¬ ì°¾ê¸°ê°€ ë„ˆë¬´ í˜ë“¤ì–´ìš”
"""

import os
import json
import numpy as np
import pandas as pd
from tqdm import tqdm
from sentence_transformers import SentenceTransformer

# --------------------------
# ê¸°ë³¸ ì„¤ì •
# --------------------------
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
FILES_DIR = os.path.join(BASE_DIR, "app", "files")
MODEL_NAME = "intfloat/multilingual-e5-base"

# SentenceTransformer ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer(MODEL_NAME)


# --------------------------
# ìœ í‹¸ í•¨ìˆ˜
# --------------------------
def normalize(vec: np.ndarray):
    """L2 ì •ê·œí™”"""
    return vec / (np.linalg.norm(vec) + 1e-12)


def chunk_text(text, max_tokens=350):
    """ê¸´ ë¬¸ì¥ì„ ì¼ì • ê¸¸ì´ë¡œ ë¶„í• """
    words = text.split()
    for i in range(0, len(words), max_tokens):
        yield " ".join(words[i:i + max_tokens])


def embed_text(text: str, prefix="query: "):
    """ë¬¸ì„œ ë˜ëŠ” ë¬¸ì¥ ì„ë² ë”©"""
    if not text or not text.strip():
        return None
    chunks = list(chunk_text(text))
    inputs = [prefix + c for c in chunks]
    embs = model.encode(inputs, normalize_embeddings=True)
    vec = np.mean(embs, axis=0)
    return normalize(vec).tolist()


# --------------------------
# 1ï¸âƒ£ ì •ì±… ë¬¸ì„œ ë²¡í„°í™”
# --------------------------
def generate_policy_vectors():
    input_path = os.path.join(FILES_DIR, "policy_corpus.txt")
    output_path = os.path.join(FILES_DIR, "policy_vectors.json")

    if not os.path.exists(input_path):
        print(f"âš ï¸ ì •ì±… ë¬¸ì„œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        return

    print(f"[vector_generator] ì •ì±… ë¬¸ì„œ ì„ë² ë”© ì¤‘... ({MODEL_NAME})")
    out = {}

    with open(input_path, "r", encoding="utf-8") as f:
        lines = [l.strip() for l in f.readlines() if l.strip()]

    for line in tqdm(lines):
        if ":" in line:
            name, text = line.split(":", 1)
        else:
            name, text = f"ì •ì±…_{len(out)+1}", line

        v = embed_text(text, prefix="passage: ")
        if v is not None:
            out[name.strip()] = v

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(out, f, ensure_ascii=False, indent=2)

    print(f"âœ… ì •ì±… ë²¡í„° ì €ì¥ ì™„ë£Œ: {output_path}")


# --------------------------
# 2ï¸âƒ£ ì§€ì—­ë³„ CSV â†’ ë²¡í„° ë³€í™˜
# --------------------------
def generate_region_vectors_from_csv():
    """CSV íŒŒì¼ì„ ì§ì ‘ ì„ë² ë”©í•˜ì—¬ *_vectors_e5.json ìƒì„±"""
    csv_files = [f for f in os.listdir(FILES_DIR) if f.endswith(".csv")]

    for csv_file in csv_files:
        region_name = csv_file.replace(".csv", "")
        csv_path = os.path.join(FILES_DIR, csv_file)
        dst_path = os.path.join(FILES_DIR, f"{region_name}_vectors_e5.json")

        print(f"[vector_generator] {region_name}.csv â†’ {region_name}_vectors_e5.json ë³€í™˜ ì¤‘...")

        try:
            df = pd.read_csv(csv_path, encoding="utf-8")
        except UnicodeDecodeError:
            df = pd.read_csv(csv_path, encoding="cp949")

        if "topic" not in df.columns or "text" not in df.columns:
            print(f"âš ï¸ {region_name}.csv íŒŒì¼ì— 'topic' ë˜ëŠ” 'text' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        topic_dict = {}
        for _, row in tqdm(df.iterrows(), total=len(df)):
            topic = str(row["topic"]).strip()
            text = str(row["text"]).strip()
            if not topic or not text:
                continue
            v = embed_text(text)
            if v is not None:
                topic_dict.setdefault(topic, []).append(v)

        if not topic_dict:
            print(f"âš ï¸ {region_name}.csvì—ì„œ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        topic_avg = {
            topic: {
                "vector": np.mean(vectors, axis=0).tolist(),
                "sample_count": len(vectors)
            }
            for topic, vectors in topic_dict.items()
        }

        with open(dst_path, "w", encoding="utf-8") as f:
            json.dump(topic_avg, f, ensure_ascii=False, indent=2)

        print(f"âœ… {region_name}_vectors_e5.json ì €ì¥ ì™„ë£Œ ({len(topic_avg)}ê°œ ì£¼ì œ)")


# --------------------------
# ì‹¤í–‰ ì§„ì…ì 
# --------------------------
if __name__ == "__main__":
    print("ğŸš€ Welling Vector Generator ì‹œì‘")

    # ì •ì±… ë²¡í„° ìƒì„±
    generate_policy_vectors()

    # ì§€ì—­ CSV íŒŒì¼ ê¸°ë°˜ ë²¡í„° ìƒì„±
    generate_region_vectors_from_csv()

    print("ğŸ‰ ëª¨ë“  ë²¡í„° ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
