"""
Welling Vector Generator (E5 ê¸°ë°˜)
-----------------------------------
âœ… ì—­í• :
- ì •ì±… ë¬¸ì„œ â†’ policy_vectors.json ìƒì„±
- ì§€ì—­ë³„ ì—¬ë¡  ë°ì´í„° â†’ {region}_vectors.json ìƒì„±
- ê¸°ì¡´ app/files í´ë” êµ¬ì¡°ì— ë§ì¶¤í˜•ìœ¼ë¡œ ë™ì‘

âœ… ìš”êµ¬ì‚¬í•­:
- app/files/policy_corpus.txt   â†’ ì •ì±… ì›ë¬¸ í…ìŠ¤íŠ¸ íŒŒì¼
- app/files/sentiment_dataset.csv â†’ ì§€ì—­ë³„ ì—¬ë¡  í…ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
- app/files í´ë”ì— 17ê°œ ì‹œë„ëª… ë°ì´í„°ì…‹ ì¡´ì¬
"""

import os
import json
import numpy as np
from tqdm import tqdm
from sentence_transformers import SentenceTransformer

# --------------------------
# ê¸°ë³¸ ì„¤ì •
# --------------------------
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
FILES_DIR = os.path.join(BASE_DIR, "app", "files")
MODEL_NAME = "intfloat/multilingual-e5-base"

# SentenceTransformer ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer(MODEL_NAME)


# --------------------------
# ìœ í‹¸ í•¨ìˆ˜
# --------------------------
def normalize(vec: np.ndarray):
    """L2 ì •ê·œí™”"""
    return vec / (np.linalg.norm(vec) + 1e-12)


def chunk_text(text, max_tokens=350):
    """ê¸´ ë¬¸ì¥ì„ ì¼ì • ê¸¸ì´ë¡œ ë¶„í• """
    words = text.split()
    for i in range(0, len(words), max_tokens):
        yield " ".join(words[i:i + max_tokens])


def embed_text(text: str, prefix="passage: "):
    """ë¬¸ì„œ ë˜ëŠ” ë¬¸ì¥ ì„ë² ë”©"""
    if not text or not text.strip():
        return None
    chunks = list(chunk_text(text))
    inputs = [prefix + c for c in chunks]
    embs = model.encode(inputs, normalize_embeddings=True)
    vec = np.mean(embs, axis=0)
    return normalize(vec).tolist()


# --------------------------
# 1ï¸âƒ£ ì •ì±… ë¬¸ì„œ ë²¡í„°í™”
# --------------------------
def generate_policy_vectors():
    input_path = os.path.join(FILES_DIR, "policy_corpus.txt")
    output_path = os.path.join(FILES_DIR, "policy_vectors.json")

    if not os.path.exists(input_path):
        print(f"âš ï¸ ì •ì±… ë¬¸ì„œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        return

    print(f"[vector_generator] ì •ì±… ë¬¸ì„œ ì„ë² ë”© ì¤‘... ({MODEL_NAME})")
    out = {}

    with open(input_path, "r", encoding="utf-8") as f:
        lines = [l.strip() for l in f.readlines() if l.strip()]

    for line in tqdm(lines):
        # "ì •ì±…ëª…: ë‚´ìš©" í˜•íƒœë¡œ ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
        if ":" in line:
            name, text = line.split(":", 1)
        else:
            name, text = f"ì •ì±…_{len(out)+1}", line

        v = embed_text(text, prefix="passage: ")
        if v is not None:
            out[name.strip()] = v

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(out, f, ensure_ascii=False, indent=2)

    print(f"âœ… ì •ì±… ë²¡í„° ì €ì¥ ì™„ë£Œ: {output_path}")


# --------------------------
# 2ï¸âƒ£ ì§€ì—­ë³„ ì—¬ë¡  ë²¡í„°í™”
# --------------------------
def generate_region_vectors():
    """ê¸°ì¡´ 17ê°œ ì§€ì—­ *_vectors.json ìë™ ìƒì„±"""
    regions = [
        "ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…",
        "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼"
    ]

    for region in regions:
        src_path = os.path.join(FILES_DIR, f"{region}_vectors.json")
        dst_path = os.path.join(FILES_DIR, f"{region}_vectors_e5.json")

        if not os.path.exists(src_path):
            print(f"âš ï¸ {region}_vectors.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            continue

        with open(src_path, "r", encoding="utf-8") as f:
            region_data = json.load(f)

        print(f"[vector_generator] {region} ì—¬ë¡  ë²¡í„° ì¬ìƒì„± ì¤‘...")
        topic_dict = {}

        # í˜•íƒœì— ë”°ë¼ ìë™ ì¸ì‹ (list ë˜ëŠ” dict)
        if isinstance(region_data, list):
            iterable = region_data
        elif isinstance(region_data, dict):
            iterable = [{"topic": t, "text": d.get("text", "")} for t, d in region_data.items()]
        else:
            print(f"âš ï¸ {region} ë°ì´í„° êµ¬ì¡° ì¸ì‹ ì‹¤íŒ¨")
            continue

        for item in tqdm(iterable):
            topic = item.get("topic")
            text = item.get("text")
            if not topic or not text:
                continue
            v = embed_text(text, prefix="query: ")
            if v is not None:
                topic_dict.setdefault(topic, []).append(v)

        topic_avg = {
            topic: {
                "vector": np.mean(vectors, axis=0).tolist(),
                "sample_count": len(vectors)
            }
            for topic, vectors in topic_dict.items()
        }

        with open(dst_path, "w", encoding="utf-8") as f:
            json.dump(topic_avg, f, ensure_ascii=False, indent=2)

        print(f"âœ… {region}_vectors_e5.json ì €ì¥ ì™„ë£Œ ({len(topic_avg)}ê°œ í† í”½)")


# --------------------------
# ì‹¤í–‰ ì§„ì…ì 
# --------------------------
if __name__ == "__main__":
    print("ğŸš€ Welling Vector Generator ì‹œì‘")

    # ì •ì±… ë²¡í„° ìƒì„±
    generate_policy_vectors()

    # ì§€ì—­ë³„ ì—¬ë¡  ë²¡í„° ìƒì„±
    generate_region_vectors()

    print("ğŸ‰ ëª¨ë“  ë²¡í„° ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
